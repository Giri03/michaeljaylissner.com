<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Michael Jay Lissner</title><link href="http://michaeljaylissner.com/" rel="alternate"></link><link href="http://michaeljaylissner.com/feeds/tag/book" rel="self"></link><id>http://michaeljaylissner.com/</id><updated>2008-06-12T18:56:49-07:00</updated><entry><title>On Memories</title><link href="http://michaeljaylissner.com/posts/2008/06/12/on-memory/" rel="alternate"></link><updated>2008-06-12T18:56:49-07:00</updated><author><name>Michael Lissner</name></author><id>tag:michaeljaylissner.com,2008-06-12:posts/2008/06/12/on-memory/</id><summary type="html">&lt;p&gt;As we progress in science, the time is going to come when we can transfer memories from one person to another.  They exist in some material form (as proteins I believe), and thus should be measurable, copyable, etc.&lt;/p&gt;
&lt;p&gt;One interesting thing however that was captured both in an excellent &lt;a href="http://www.wnyc.org/shows/radiolab/episodes/2008/02/14"&gt;Radiolab show&lt;/a&gt;, and in Cormac McCarthy's &lt;em&gt;The Road&lt;/em&gt;, is the destructive power of recalling a memory.&lt;/p&gt;
&lt;p&gt;It's interesting. As McCarthy states, "...each memory recalled must do some violence to its origins." According to Radiolab, McCarthy is right on the money. In their show, they explain that as we think about a memory, really we are constructing it from fragments of that memory, recreating how we imagine it was. Unfortunately though, the next time that we recall that memory, we lose some accuracy because we can't quite keep track of which parts we constructed the last time, and which parts were there from the beginning.&lt;/p&gt;
&lt;p&gt;This is why people who dwell on a memory, or are repeatedly asked to recall the same thing, will quickly forget what was fact, and what they constructed. It's not that they are making things up, per se, it's just that what they believe, and what they constructed have merged.&lt;/p&gt;
&lt;p&gt;So, what's the best way to remember your first kiss, or your the face of a loved one lost? Don't think about it - unless, of course, you're sure you want to.&lt;/p&gt;</summary><category term="book"></category><category term="radiolab"></category><category term="memory"></category></entry><entry><title>The Singularity Is Near</title><link href="http://michaeljaylissner.com/posts/2007/10/12/the-singularity-is-near/" rel="alternate"></link><updated>2007-10-12T22:53:24-07:00</updated><author><name>Michael Lissner</name></author><id>tag:michaeljaylissner.com,2007-10-12:posts/2007/10/12/the-singularity-is-near/</id><summary type="html">&lt;p&gt;I know what you're thinking: "The Singularity - What is Mike talking about? This must be stupid." I'm here to say that it might be stupid, but bear with me because I can't decide if it is, and I need to know the public consensus. &lt;/p&gt;
&lt;p&gt;The Singularity is this theory I have been reading far too much about that there will come a time when "computers transcend biology." Think about that for a moment: computers...transcend...biology. In other words, there will come a time when computers are so advanced that they have moved beyond the limitations of biology; beyond what we now think of as computers, and into some biocomputing nano-thing.&lt;/p&gt;
&lt;p&gt;The book I'm reading right now is &lt;em&gt;The Singularity is Near&lt;/em&gt; by Ray Kurzweil. It sounds like a joke, and you'd think he was some two-bit writer that didn't cite his references, or that didn't know his shit, but sadly, the book has over 100 pages of references, and the man teaches at Stanford. So he's qualified to write about crazy future ideas. &lt;/p&gt;
&lt;p&gt;Imagine if technological change occurred at an exponentially exponential rate (crazy, I know), and that in about 33 years - give or take - we will experience the Singularity. At that point, computers will be able to build themselves. Software will write itself, and because it is being written by software that doesn't make mistakes like ordinary humans, new versions and steps forward in technology will happen so quickly that we won't be able to keep up. It sounds crazy at first, but then you start to think about it: We have programming languages, and we have Integrated Development Environments that help us mortals to write software. Is it so crazy to think that the two might merge, and that software might write itself? &lt;/p&gt;
&lt;p&gt;Yes? OK, you're probably referring to the fact that computers don't have creative powers. This is true, but, like a child, they can learn language autonomously, and build themselves autonomously already. For example, out here in the Bay Area, we're near Google, who has just rolled out a new service called Goog-411. Basically, you call 1-800-Goog-411, and a machine will record your voice, ask you what location and business name. It will then (seemingly without fail), give you the phone number for the location, and connect you (for free). It's great, and what's more amazing is that the success of your call teaches the computer how to better help the next person. The more people call, the better it works.&lt;/p&gt;
&lt;p&gt;So, we have computers that can build themselves already, and we have computers that could theoretically write themselves from the ground up. Imagine if we had computers that could analyze the news, and attempt to fix problems. &lt;/p&gt;
&lt;p&gt;All of the above seems plausible to me, more or less. I mean, forty years ago, we didn't even have computers. Now we have ones that can write the &lt;a href="http://www.soe.ucsc.edu/pipermail/genome/2000-July/000021.html"&gt;entire human genome on a CD&lt;/a&gt;, or if you prefer, it can do it eight or nine times on a DVD.  That's all the information needed to create a human. On a CD. Is it so crazy to believe that computers will be able to do what we humans can? I'm not so skeptical any more. Will the timing be around 2040...I think it may. Freaky.&lt;/p&gt;</summary><category term="singularity"></category><category term="book"></category><category term="infotech"></category></entry></feed>